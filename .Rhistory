start = 1994
end = 2020
for (yr in start:end){
print(yr)
path = paste0(raw_dir,"br/br",yr,".csv" )
br_dt_temp = as.data.table(fread(path)) %>% filter(nchar(as.character(ENT_ID) )==9) %>%
rename( firmid = ENT_ID, NACE_BR = NACE_M) %>%
mutate(birth_year = as.numeric(str_sub(str_trim(as.character(Start_Ent)),-4,-1)),
birth_year = ifelse(birth_year>=1900 & birth_year<=yr, birth_year, NA),
firmid = as.numeric(firmid)) %>%
select(firmid, NACE_BR, year, birth_year)
if (yr== start){
br_dt = br_dt_temp
}else{
br_dt = rbind(br_dt,br_dt_temp)
}
}
br_dt = br_dt %>% arrange(firmid, year)
br_dt = br_dt %>% group_by(firmid) %>% mutate(death_year = ifelse(max(year)==end, NA, max(year))) %>% ungroup()
for (yr in start:end){
br_dt_temp = br_dt %>% filter(year == yr)
write.csv(br_dt_temp, paste0(realloc_dir,'br_cleaned/br_cleaned_,',yr,'.csv'), row.names = F)
}
# libraries
rm(list = ls())
library(data.table)
library(haven)
library(readxl)
library(openxlsx)
library(stringr)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(zoo)
library(tictoc)
raw_dir = "C:/Users/Public/1. Microprod/0. Raw data processing/Data/"
realloc_dir = 'C:/Users/NEWPROD_A_MAGNUSO/Documents/Reallocation_work/2 Data/'
big_data_dir = 'C:/Users/NEWPROD_A_MAGNUSO/Documents/Big data Project/1) Data/'
# Generate Born / Died and dominant NACE from BR  -------------------------------------------
start = 1994
end = 2020
for (yr in start:end){
print(yr)
path = paste0(raw_dir,"br/br",yr,".csv" )
br_dt_temp = as.data.table(fread(path)) %>% filter(nchar(as.character(ENT_ID) )==9) %>%
rename( firmid = ENT_ID, NACE_BR = NACE_M) %>%
mutate(birth_year = as.numeric(str_sub(str_trim(as.character(Start_Ent)),-4,-1)),
birth_year = ifelse(birth_year>=1900 & birth_year<=yr, birth_year, NA),
firmid = as.numeric(firmid)) %>%
select(firmid, NACE_BR, year, birth_year)
if (yr== start){
br_dt = br_dt_temp
}else{
br_dt = rbind(br_dt,br_dt_temp)
}
}
br_dt = br_dt %>% arrange(firmid, year)
br_dt = br_dt %>% group_by(firmid) %>% mutate(death_year = ifelse(max(year)==end, NA, max(year))) %>% ungroup()
for (yr in start:end){
br_dt_temp = br_dt %>% filter(year == yr)
write.csv(br_dt_temp, paste0(realloc_dir,'br_cleaned/br_cleaned_,',yr,'.csv'), row.names = F)
}
for (yr in start:end){
print(year)
br_dt_temp = br_dt %>% filter(year == yr)
write.csv(br_dt_temp, paste0(realloc_dir,'br_cleaned/br_cleaned_',yr,'.csv'), row.names = F)
}
for (yr in start:end){
print(yr)
br_dt_temp = br_dt %>% filter(year == yr)
write.csv(br_dt_temp, paste0(realloc_dir,'br_cleaned/br_cleaned_',yr,'.csv'), row.names = F)
}
data = fread( '../1) data/3_bs_br_data.csv',nrows = 1000, colClasses = list(character= 'firmid')) %>% na.omit()
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64','tmvtnorm'
)
lapply(packages, function(package){
tryCatch({library(package,character.only = T)}, error = function(cond){
install.packages(package); library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("00_helper_functions.R")
raw_dir = 'C:/Users/Public/1. Microprod/0. Raw data processing/Data/'
data = fread( '../1) data/3_bs_br_data.csv',nrows = 1000, colClasses = list(character= 'firmid')) %>% na.omit()
data[, count:= .N, by = .(NACE_BR, year)]; data = data[count > firm_id_threshold]; data[, count :=NULL ]
# 0) parameters / helper functions---------------------------------------------------------
firm_id_threshold = 4; set.seed(1)
generate_discrete_samples = function(data, data_dummy, group_vars, interest_vars){
# use the group vars to generate unique ids fro each group
group_keys = data[, ..group_vars] %>% unique() %>% mutate(group_code = 1:nrow(.))
data = merge(data, group_keys)
data_dummy = merge(data_dummy, group_keys)
# for each group use the joint empirical distribution of values to generate
data_dummy = lapply(1:nrow(group_keys), function(i){
temp_dummy = data_dummy[group_code == i]; num_in_dummy = nrow(temp_dummy)
if (num_in_dummy > 0){
temp = data[group_code == i, ..interest_vars]; num_in_temp = nrow(temp);
temp_dummy = cbind(temp_dummy,temp[sample(1:num_in_temp, num_in_dummy, T)])
}
return(temp_dummy)
}) %>% rbindlist(fill =T, use.names = T)
data[, group_code := NULL]; data_dummy[, group_code := NULL]
return(data_dummy)
}
simulate_continuous_vars = function(data, data_dummy, group_vars, interest_vars){
# use the group vars to generate unique ids fro each group
group_keys = data[, ..group_vars] %>% unique() %>% mutate(group_code = 1:nrow(.))
data = merge(data, group_keys)
data_dummy = merge(data_dummy, group_keys)
# generate the mins and maxes for the whole dataset, these will serve as bounds
# for the simulation draws
mins = apply(data[,..interest_vars],2, NA_min); maxes = apply(data[,..interest_vars],2, NA_max)
# for each group generate the multivariate normal distribution of the variables of interest
data_dummy = lapply(1:nrow(group_keys), function(i){
temp_dummy = data_dummy[group_code == i]; num_in_dummy = nrow(temp_dummy)
if (num_in_dummy > 0){
temp = data[group_code == i, ..interest_vars]
## ensure covariance matrix is positive definite
noise = rnorm(nrow(temp)*length(interest_vars),0, 1e-6) %>% matrix(., nrow = nrow(temp))
noise = noise - min(noise);temp = temp+ noise
cov_matrix = cov(temp, use = 'pairwise.complete.obs') %>% nearPD()
cov_matrix = cov_matrix$mat
# simulate data
draws = rtmvnorm(num_in_dummy, colMeans(temp, na.rm = T),cov_matrix,mins,maxes)
temp_dummy[,(interest_vars) := as.data.table(draws)]
}
return(temp_dummy)
}) %>% rbindlist(fill =T, use.names = T)
return(data_dummy)
}
# 1) BS BR data -----------------------------------------------------------
data = fread( '../1) data/3_bs_br_data.csv',nrows = 1000, colClasses = list(character= 'firmid')) %>% na.omit()
data[, count:= .N, by = .(NACE_BR, year)]; data = data[count > firm_id_threshold]; data[, count :=NULL ]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data)
year_nace = data[, .(NACE_BR, year)]
# for each obs. randomly assign an id and then draw from the joint distrib of year-NACE industry combinations
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T)) %>%
cbind(.,year_nace[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining vars draw from joint distribution for each group (all groups contain >= 4 members)
interest_vars = setdiff( names(data),c('empl_bucket',names(data_dummy)))
group_vars = c('NACE_BR', 'year')
data_dummy = simulate_continuous_vars(data, data_dummy, group_vars, interest_vars)
# add any vars still missing
data_dummy[, empl_bucket := ifelse(empl < 10, "0-10", ifelse(empl < 50, '10-50',
ifelse(empl < 200, '50-200', ifelse(empl >=200, '200+', NA))))]
setdiff(names(data),names(data_dummy))
data = fread( '../1) data/4_OFATS.csv', colClasses = list(character= 'firmid')) %>% na.omit()
group_vars = c('ctryofats', 'year')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL ]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
group_distrib = data[, ..group_vars]
# for each obs. randomly assign an id and then draw from the joint distrib of year-NACE industry combinations
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining vars draw from joint distribution for each group (all groups contain >= 4 members)
interest_vars = setdiff( names(data),c('name',names(data_dummy)))
data_dummy = simulate_continuous_vars(data, data_dummy, group_vars, interest_vars)
setdiff(names(data),names(data_dummy))
# setup
rm(list = ls())
packages = c('data.table', 'haven', 'readxl', 'openxlsx', 'stringr', 'readr', 'dplyr',
'tidyverse', 'janitor', 'Matrix','parallel', 'bigmemory','bit64','tmvtnorm'
)
lapply(packages, function(package){
tryCatch({library(package,character.only = T)}, error = function(cond){
install.packages(package); library(package, character.only = T)
})})
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("00_helper_functions.R")
raw_dir = 'C:/Users/Public/1. Microprod/0. Raw data processing/Data/'
# 0) parameters / helper functions---------------------------------------------------------
firm_id_threshold = 4; set.seed(1)
simulate_discrete_vars = function(data, data_dummy, group_vars, interest_vars){
# use the group vars to generate unique ids fro each group
group_keys = data[, ..group_vars] %>% unique() %>% mutate(group_code = 1:nrow(.))
data = merge(data, group_keys)
data_dummy = merge(data_dummy, group_keys)
# for each group use the joint empirical distribution of values to generate
data_dummy = lapply(1:nrow(group_keys), function(i){
temp_dummy = data_dummy[group_code == i]; num_in_dummy = nrow(temp_dummy)
if (num_in_dummy > 0){
temp = data[group_code == i, ..interest_vars]; num_in_temp = nrow(temp);
temp_dummy = cbind(temp_dummy,temp[sample(1:num_in_temp, num_in_dummy, T)])
}
return(temp_dummy)
}) %>% rbindlist(fill =T, use.names = T)
data[, group_code := NULL]; data_dummy[, group_code := NULL]
return(data_dummy)
}
simulate_continuous_vars = function(data, data_dummy, group_vars, interest_vars){
# use the group vars to generate unique ids fro each group
group_keys = data[, ..group_vars] %>% unique() %>% mutate(group_code = 1:nrow(.))
data = merge(data, group_keys)
data_dummy = merge(data_dummy, group_keys)
# generate the mins and maxes for the whole dataset, these will serve as bounds
# for the simulation draws
mins = apply(data[,..interest_vars],2, NA_min); maxes = apply(data[,..interest_vars],2, NA_max)
# for each group generate the multivariate normal distribution of the variables of interest
data_dummy = lapply(1:nrow(group_keys), function(i){
temp_dummy = data_dummy[group_code == i]; num_in_dummy = nrow(temp_dummy)
if (num_in_dummy > 0){
temp = data[group_code == i, ..interest_vars]
## ensure covariance matrix is positive definite
noise = rnorm(nrow(temp)*length(interest_vars),0, 1e-6) %>% matrix(., nrow = nrow(temp))
noise = noise - min(noise);temp = temp+ noise
cov_matrix = cov(temp, use = 'pairwise.complete.obs') %>% nearPD()
cov_matrix = cov_matrix$mat
# simulate data
draws = rtmvnorm(num_in_dummy, colMeans(temp, na.rm = T),cov_matrix,mins,maxes)
temp_dummy[,(interest_vars) := as.data.table(draws)]
}
return(temp_dummy)
}) %>% rbindlist(fill =T, use.names = T)
return(data_dummy)
}
data = fread(nrows = 10000,'../1) data/9_customs_cleaned.csv')
group_vars = c('exim', 'ctry', 'year', 'birth_year','firm_age', 'birth_observed',
'streak_start', 'streak_length', 'streak_birth_observed', 'year_in_streak')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL ]
group_distrib = data[, ..group_vars]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
num_streaks = data[!duplicated(streak_id)] %>% nrow();
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T),
streak_id = sample(1:num_streaks, num_data_points, T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining discrete vars simulate data using observed empirical distrib (all groups contain >= 4 members)
base = c('_portfolio_key', '_region', '_language', '_border')  # latter values fully determined by portfolio key
varlist = list(paste0('export',base),  paste0('import',base),
paste0('import',base,"_lag1"), paste0('export',base,"_lag1"),
c('import_hs_class', 'export_hs_class'), 'first_import_year', 'first_export_year')
for(interest_vars in varlist){
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, interest_vars)
}
data = fread(nrows = 10000,'../1) data/9_customs_cleaned.csv')
group_vars = c('exim', 'ctry', 'year', 'birth_year','firm_age', 'birth_observed',
'streak_start', 'streak_length', 'streak_birth_observed', 'year_in_streak')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL ]
group_distrib = data[, ..group_vars]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
num_streaks = data[!duplicated(streak_id)] %>% nrow();
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T),
streak_id = sample(1:num_streaks, num_data_points, T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining discrete vars simulate data using observed empirical distrib (all groups contain >= 4 members)
base = c('_region', '_language', '_border')
varlist = list(paste0('export',base),  paste0('import',base),
paste0('import',base,"_lag1"), paste0('export',base,"_lag1"),
c('import_hs_class', 'export_hs_class'), 'first_import_year', 'first_export_year')
for(interest_vars in varlist){
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, interest_vars)
}
interest_vars = setdiff( names(data),c('import_portfolio_key_lag',names(data_dummy)))
data_dummy = simulate_continuous_vars(data, data_dummy, group_vars, interest_vars)
setdiff(names(data),names(data_dummy))
data = fread(nrows = 100000,'../1) data/10_product_export_streaks.csv')
data = fread(nrows = 100000,'../1) data/10_customs_product_level_cleaned.csv')
group_vars = c('exim', 'ctry', 'year', 'birth_year','firm_age', 'birth_observed',
'streak_start', 'streak_length', 'streak_birth_observed', 'year_in_streak')
data = fread(nrows = 100000,'../1) data/10_customs_product_level_cleaned.csv')
group_vars = c('exim', 'ctry', 'year', 'birth_year','firm_age', 'birth_observed',
'streak_start', 'streak_length', 'streak_birth_observed', 'year_in_streak')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL]
names(data)
data = fread(nrows = 10000,'../1) data/9_customs_cleaned.csv')
data = fread(nrows = 1000,'../1) data/9_customs_cleaned.csv')
group_vars = c('exim', 'ctry', 'year', 'birth_year','firm_age', 'birth_observed',
'streak_start', 'streak_length', 'streak_birth_observed', 'year_in_streak',
'streak_death_observed')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL ]
data = fread(nrows = 1000,'../1) data/9_customs_cleaned.csv')
group_vars = c('exim', 'ctry', 'year', 'birth_year','firm_age', 'birth_observed',
'streak_start', 'streak_length', 'streak_birth_observed', 'year_in_streak',
'streak_death_observed')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL ]
group_distrib = data[, ..group_vars]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
num_streaks = data[!duplicated(streak_id)] %>% nrow();
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T),
streak_id = sample(1:num_streaks, num_data_points, T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining discrete vars simulate data using observed empirical distrib (all groups contain >= 4 members)
base = c('_region', '_language', '_border')
varlist = list(paste0('export',base),  paste0('import',base),
paste0('import',base,"_lag1"), paste0('export',base,"_lag1"),
c('import_hs_class', 'export_hs_class'), 'first_import_year', 'first_export_year')
for(interest_vars in varlist){
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, interest_vars)
}
interest_vars = setdiff( names(data),c('import_portfolio_key_lag',names(data_dummy)))
data_dummy = simulate_continuous_vars(data, data_dummy, group_vars, interest_vars)
setdiff(names(data),names(data_dummy))
names(dataa)
names(data)
group_vars = c("ctry","exim","year", "streak_birth_observed" ,"streak_death_observed" ,
'streak_start',"year_in_streak", "streak_length")
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL]
group_distrib = data[, ..group_vars]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
num_streaks = data[!duplicated(streak_id)] %>% nrow();
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T),
streak_id = sample(1:num_streaks, num_data_points, T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
setdiff(names(data),names(data_dummy))
base = c('_region', '_language', '_border')
varlist = list(paste0('export',base),  paste0('import',base),
paste0('import',base,"_lag1"), paste0('export',base,"_lag1"),
c('import_hs_class', 'export_hs_class'), 'first_import_year', 'first_export_year')
for(interest_vars in varlist){
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, interest_vars)
}
setdiff( names(data),c('import_portfolio_key_lag',names(data_dummy)))
data = fread(nrows = 100000,'../1) data/10_customs_product_level_cleaned.csv')
group_vars = c("ctry","exim","year", "streak_birth_observed" ,"streak_death_observed" ,
'streak_start',"year_in_streak", "streak_length")
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL]
group_distrib = data[, ..group_vars]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
num_streaks = data[!duplicated(streak_id)] %>% nrow();
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T),
streak_id = sample(1:num_streaks, num_data_points, T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining vars draw from joint distribution for each group (all groups contain >= 4 members)
base = c('_region', '_language', '_border')
varlist = list(paste0('export',base),  paste0('import',base),
paste0('import',base,"_lag1"), paste0('export',base,"_lag1"),
c('import_hs_class', 'export_hs_class'), 'first_import_year', 'first_export_year')
for(interest_vars in varlist){
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, interest_vars)
}
names(data)
interest_vars = setdiff( names(data),c(names(data_dummy)))
interest_vars
data_dummy = simulate_discrete_vars(data, data_dummy,'CN8plus', interest_vars)
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, 'CN8plus')
data_dummy[,hs_class := substr(CN8plus,1,2)]
interest_vars = setdiff( names(data),names(data_dummy))
interest_vars
data = fread(nrows = 100000,'../1) data/10_customs_product_level_cleaned.csv')
group_vars = c("ctry","exim","year", "streak_birth_observed" ,"streak_death_observed" ,
'streak_start',"year_in_streak", "streak_length", 'birth_observed')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL]
group_distrib = data[, ..group_vars]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
num_streaks = data[!duplicated(streak_id)] %>% nrow();
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T),
streak_id = sample(1:num_streaks, num_data_points, T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining vars simulate from observed distribution (all groups contain >= 4 members)
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, 'CN8plus')
data_dummy[,hs_class := substr(CN8plus,1,2)]
interest_vars = setdiff( names(data),names(data_dummy))
data_dummy = simulate_continuous_vars(data, data_dummy, group_vars, interest_vars)
data = fread(nrows = 100000,'../1) data/10_customs_product_level_cleaned.csv') %>% na.omit()
group_vars = c("ctry","exim","year", "streak_birth_observed" ,"streak_death_observed" ,
'streak_start',"year_in_streak", "streak_length", 'birth_observed')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL]
group_distrib = data[, ..group_vars]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
num_streaks = data[!duplicated(streak_id)] %>% nrow();
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T),
streak_id = sample(1:num_streaks, num_data_points, T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining vars simulate from observed distribution (all groups contain >= 4 members)
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, 'CN8plus')
data_dummy[,hs_class := substr(CN8plus,1,2)]
interest_vars = setdiff( names(data),names(data_dummy))
data_dummy = simulate_continuous_vars(data, data_dummy, group_vars, interest_vars)
interest_vars
View(data)
View(data)
data[,placeholder :=1]; data_dummy[placehlder := 1];
data[,placeholder :=1]; data_dummy[,placeholder := 1];
data_dummy = simulate_continuous_vars(data, data_dummy, 'placeholder', interest_vars)
data = fread(nrows = 100000,'../1) data/10_customs_product_level_cleaned.csv')
group_vars = c("ctry","exim","year", "streak_birth_observed" ,"streak_death_observed" ,
'streak_start',"year_in_streak", "streak_length", 'birth_observed')
data[, count:= .N, by = group_vars]; data = data[count > firm_id_threshold]; data[, count :=NULL]
group_distrib = data[, ..group_vars]
num_firms = data[!duplicated(firmid)] %>% nrow(); num_data_points = nrow(data);
num_streaks = data[!duplicated(streak_id)] %>% nrow();
data_dummy = data.table(firmid = sample(1:num_firms, num_data_points,  T),
streak_id = sample(1:num_streaks, num_data_points, T)) %>%
cbind(.,group_distrib[sample(1:num_data_points, num_data_points, T)]) %>% unique()
# for remaining vars simulate from observed distribution (all groups contain >= 4 members)
data_dummy = simulate_discrete_vars(data, data_dummy,group_vars, 'CN8plus')
data_dummy[,hs_class := substr(CN8plus,1,2)]
interest_vars = setdiff( names(data),names(data_dummy))
data[,placeholder :=1]; data_dummy[,placeholder := 1];
data_dummy = simulate_continuous_vars(data, data_dummy, 'placeholder', interest_vars)
data_dummy[,placeholder := NULL]
setdiff( names(data),names(data_dummy))
data = fread('../1) data/10a_product_lvl_summary_stats.csv')
data[1:10]
filepath = '../1) data/10a_product_lvl_summary_stats.csv'
fread(filepath)[cn8_ctry_num_firms > firm_id_threshold] %>% fwrite(gsub('1) data','1a) dummy data',filepath))
filepath = '../1) data/11_country_level_data.csv'
fread(filepath)[hs_ctry_num_firms > firm_id_threshold] %>% fwrite(gsub('1) data','1a) dummy data',filepath))
product_collapsed = fread( '../1) data/10a_product_lvl_summary_stats.csv')[exim ==2 & CN8_ctry_num_firms > 0][,exim:= NULL]
product_collapsed = fread( '../1) data/10a_product_lvl_summary_stats.csv')[exim ==2 & cn8_ctry_num_firms > 0][,exim:= NULL]
product_collapsed = fread( '../1) data/10a_product_lvl_summary_stats.csv')[exim ==2 ][,exim:= NULL]
product_collapsed = fread( '../1) data/10a_product_lvl_summary_stats.csv')[exim ==2 & cn8_ctry_num_firms > 0][,exim:= NULL]
